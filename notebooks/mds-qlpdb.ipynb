{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# dominating set\n",
    "\n",
    "Set up calculations and store in EspressoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from qlp.mds import graph_tools as gt\n",
    "from qlp.mds.qubo import get_mds_qubo\n",
    "from qlp.mds.solver import classical_search\n",
    "from qlp.mds.mds_qlpdb import graph_summary, experiment_summary, data_summary, insert_result, QUBO_to_Ising\n",
    "\n",
    "from networkx import Graph\n",
    "from networkx.algorithms.approximation import min_weighted_dominating_set\n",
    "\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.system.composites import EmbeddingComposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Adjacency matrix\n",
    "# Hamming(d,q)\n",
    "# Biparti\n",
    "# NN(v): 1D nearest neighbor with v vertices. max is 16 before minor embedding starts breaking\n",
    "#graph, tag = gt.generate_hamming_graph(1, 2)\n",
    "#graph, tag = gt.generate_bipartite_graph(3, 3)\n",
    "for nvertices in range(4,5):\n",
    "    graph, tag = gt.generate_erdos_renyi_graph(nvertices, 0.1)\n",
    "    penalty = 2\n",
    "\n",
    "    directed = False\n",
    "    qubo = get_mds_qubo(graph, directed=directed, penalty = penalty, triangularize=True, dtype=\"d\")\n",
    "    q_min = np.array(list(qubo.values())).min()\n",
    "\n",
    "    gt.get_plot(graph, directed=directed)\n",
    "    plt.show()\n",
    "    graph_params = graph_summary(tag, graph)\n",
    "    print(graph_params)\n",
    "\n",
    "    # Experiment\n",
    "    J, h, C = QUBO_to_Ising(qubo.todense().tolist())\n",
    "    maxJ = max(abs(J).flatten())\n",
    "    maxh = max(abs(h))\n",
    "    #print(\"Initial\")\n",
    "    #print(f\"max(J) = {maxJ}\")\n",
    "    #print(f\"max(h) = {maxh}\")\n",
    "    #print(\"DWave J_range = [-1.0, 1.0] \\nDWave h_range = [-2.0, 2.0]\")\n",
    "    #print(\"Must scale QUBO to these ranges\\n\")\n",
    "    fact = 1 #max([maxJ, maxh/2]) * 1.2\n",
    "    qubo = qubo / fact\n",
    "\n",
    "    J, h, C = QUBO_to_Ising(qubo.todense().tolist())\n",
    "    maxJ = max(abs(J).flatten())\n",
    "    maxh = max(abs(h))\n",
    "    #print(\"Rescaled\")\n",
    "    #print(f\"max(J) = {maxJ}\")\n",
    "    #print(f\"max(h) = {maxh}\")\n",
    "    #print(\"DWave J_range = [-1.0, 1.0] \\nDWave h_range = [-2.0, 2.0]\")\n",
    "    #print(\"Must scale QUBO to these ranges\\n\")\n",
    "\n",
    "    # Set chain strength\n",
    "    chain_strength = maxJ*2\n",
    "    print(f\"Chain strength: {chain_strength}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    # DWave settings\n",
    "    dwave_config = {\n",
    "        \"annealing_time\": 500,  # integer microseconds [1, 2000]\n",
    "        \"answer_mode\": \"raw\", # histogram or raw\n",
    "        \"auto_scale\": True,\n",
    "        \"num_reads\": 1000,  # raw will dump out all results\n",
    "        \"num_spin_reversal_transforms\": 0,\n",
    "        \"readout_thermalization\": 0, # default 0\n",
    "        \"programming_thermalization\": 1000, # default 1000\n",
    "        \"chain_strength\": chain_strength\n",
    "    }\n",
    "    solver = \"DW_2000Q_5\"\n",
    "\n",
    "    experiment_params = experiment_summary(machine=solver, settings=dwave_config, penalty=penalty, factor=fact, chain_strength=chain_strength, qubo=qubo)\n",
    "\n",
    "\n",
    "    # Solve on DWave and push to database\n",
    "    sampler = DWaveSampler(solver=solver)\n",
    "    embed = EmbeddingComposite(sampler)\n",
    "    qubo_dict = {key: val for key, val in zip(qubo.keys(), qubo.values())}\n",
    "    for idx in range(10):\n",
    "        print(idx)\n",
    "        result = embed.sample_qubo(qubo_dict, **dwave_config)\n",
    "        raw = result.to_pandas_dataframe()\n",
    "        data_params = data_summary(raw, graph_params, experiment_params)\n",
    "        result = insert_result(graph_params, experiment_params, data_params)\n",
    "    print(raw.sort_values(\"energy\", ascending=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classical_search(qubo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlpdb.data.models import Data as data_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Data.objects.filter(experiment__graph__tag=\"NN(2)\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nvertices in range(3,5):\n",
    "    graph, tag = gt.generate_bipartite_graph(1, nvertices)\n",
    "    penalty = 2\n",
    "\n",
    "    directed = False\n",
    "    qubo = get_mds_qubo(graph, directed=directed, penalty = penalty, triangularize=True, dtype=\"d\")\n",
    "    q_min = np.array(list(qubo.values())).min()\n",
    "\n",
    "    gt.get_plot(graph, directed=directed)\n",
    "    plt.show()\n",
    "    graph_params = graph_summary(tag, graph)\n",
    "    print(graph_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1), (0, 5), (0, 6), (0, 9), (2, 3), (3, 8), (5, 8), (6, 8)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph, tag = gt.generate_erdos_renyi_graph(10, 0.2)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from networkx.algorithms.approximation.dominating_set import min_weighted_dominating_set\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(graph)\n",
    "min_weighted_dominating_set(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEuCAYAAADx63eqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAEiklEQVR4nO3VMQEAIAzAMMC/5+ECjiYK+nXPzCwAiDi/AwDgJeMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AFOMDIMX4AEgxPgBSjA+AlAvcsAZYWWSZ3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from networkx.drawing.nx_pylab import draw\n",
    "draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum_linear_programming",
   "language": "python",
   "name": "quantum_linear_programming"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
